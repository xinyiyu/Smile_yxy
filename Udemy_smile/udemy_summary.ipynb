{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gender-guesser in /import/home2/xyubl/.conda/envs/FAVM/lib/python3.7/site-packages (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "!pip install gender-guesser\n",
    "import gender_guesser.detector as gender\n",
    "from functools import reduce\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dependent variables and control variables\n",
    "category = 'fin'\n",
    "info = pd.read_csv('fin/x900a.csv', sep=',')\n",
    "info.rename(columns={'Id': 'Video_ID'}, inplace=True)\n",
    "## duration\n",
    "dur_df = pd.read_csv('fin/duration_freq5.csv', sep='\\t')\n",
    "## timing\n",
    "tim_df = pd.read_csv('fin/timing_3_freq5.csv', sep='\\t')\n",
    "## intensity\n",
    "inten_df = pd.read_csv('fin/intensity_freq5.csv', sep='\\t')\n",
    "## asymmetry\n",
    "asym_df = pd.read_csv('fin/asymmetry_freq5.csv', sep='\\t')\n",
    "## beauty\n",
    "beauty_df = pd.read_csv('fin/beauty_freq5.csv', sep='\\t')\n",
    "## video quality\n",
    "qua_df = pd.read_csv('fin/video_quality.txt', sep='\\t', header=None)\n",
    "qua_df.columns = ['Video_ID', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:01<00:00, 556.60it/s]\n"
     ]
    }
   ],
   "source": [
    "video_folders = ['video_1-100', 'video_101-200', 'video_201-300', 'video_301-350', 'video_351-400', 'video_401-500', \\\n",
    "                 'video_501-580', 'video_581-660', 'video_661-740', 'video_741-820', 'video_821-900']\n",
    "video_paths = [f'{category}/{x}' for x in video_folders]\n",
    "video_lookup = dict.fromkeys(video_folders)\n",
    "for i, k in enumerate(video_lookup.keys()):\n",
    "    video_lookup[k] = [os.path.splitext(x)[0] for x in os.listdir(f'/home/xyubl/Downloads/{k}')]\n",
    "video_lookup_inv = {}\n",
    "for k, v in video_lookup.items():\n",
    "    for vid in v:\n",
    "        video_lookup_inv[vid] = f'/home/xyubl/Downloads/{k}/{vid}.mp4'\n",
    "path_df = pd.DataFrame(columns=['Video_ID', 'path'])\n",
    "for k, v in tqdm(video_lookup_inv.items()):\n",
    "    path_df.loc[len(path_df)] = [k, v]\n",
    "path_df = path_df.astype({'Video_ID': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## gender estimation and manually correction: do not run\n",
    "if False:\n",
    "    d = gender.Detector()\n",
    "    gender_df = pd.DataFrame(columns=['Name_of_Tch_1', 'gender'])\n",
    "    for name in tqdm(set(info.Name_of_Tch_1.values.tolist())):\n",
    "        est = d.get_gender(name.split(' ')[0])\n",
    "        gender_df.loc[len(gender_df)] = [name, est]\n",
    "    gender_df = pd.merge(info[['Video_ID', 'Name_of_Tch_1']], gender_df[['Name_of_Tch_1', 'gender']], on='Name_of_Tch_1')\n",
    "    df = pd.merge(gender_df, path_df, on='Video_ID', how='left')\n",
    "    df.to_excel('fin/gender_estimation.xlsx', index=False)\n",
    "    gender_df = pd.read_excel('fin/gender.xlsx')\n",
    "    gender_df.to_csv('fin/gender.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gender\n",
    "gender_df = pd.read_csv('fin/gender.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## video length\n",
    "if not os.path.exists('fin/video_length.csv'):\n",
    "    video_folders = ['video_1-100', 'video_101-200', 'video_201-300', 'video_301-350', 'video_351-400', 'video_401-500', \\\n",
    "                         'video_501-580', 'video_581-660', 'video_661-740', 'video_741-820', 'video_821-900']\n",
    "    video_paths = [f'/home/xyubl/Downloads/{x}' for x in video_folders]\n",
    "    len_df = pd.DataFrame(columns=['Video_ID', 'video_length'])\n",
    "    for video_path in video_paths:\n",
    "        video_files = glob.glob(f'{video_path}/*.mp4')\n",
    "        for video_file in tqdm(video_files):\n",
    "            video_id = int(video_file.split('/')[-1].split('.')[0])\n",
    "            video = cv2.VideoCapture(video_file)\n",
    "            frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "            fps = video.get(cv2.CAP_PROP_FPS) \n",
    "            video_length = frames / fps\n",
    "            len_df.loc[len(len_df)] = [video_id, video_length]\n",
    "    len_df = len_df.astype({'Video_ID': int})\n",
    "    len_df.to_csv('fin/video_length.csv', sep='\\t', index=False)\n",
    "len_df = pd.read_csv('fin/video_length.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter information\n",
    "filter_df = pd.read_csv('fin/video_filter.csv', sep='\\t')\n",
    "use_videos = filter_df.loc[(filter_df.showup_proportion>0.2) & (filter_df.frame_land_diff>3) & (filter_df.align_land_diff>3)].Video_ID.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate all variables\n",
    "dfs = [info, dur_df[['Video_ID', 'showup', 'smile_proportion']], tim_df[['Video_ID', 'beginning', 'middle', 'end']], \n",
    "       inten_df[['Video_ID', 'Intensity']], asym_df[['Video_ID', 'asymmetry']], beauty_df[['Video_ID', 'beauty']],\n",
    "       qua_df, len_df, gender_df, path_df]\n",
    "var_df = reduce(lambda left, right: pd.merge(left, right, on='Video_ID', how='outer'), dfs)\n",
    "var_df['preview'] = (~var_df.path.isna().values).astype(int)\n",
    "showup_arr = []\n",
    "for _, row in var_df.iterrows():\n",
    "    if row.preview == 0:\n",
    "        showup_arr.append(np.nan)\n",
    "    else:\n",
    "        showup_arr.append(int(row.Video_ID in use_videos))\n",
    "var_df.showup = showup_arr\n",
    "var_df = var_df.sort_values('Video_ID').reset_index(drop=True)\n",
    "var_df['male'] = [1 if x in ['male', 'unknown'] else 0 for x in var_df.gender]\n",
    "var_df['description_length'] = var_df['Blurb'].apply(lambda x: len(x.split(' ')) if type(x) is str else 0)\n",
    "var_df['log_description_length'] = [np.log(x) if x != 0 else 0 for x in var_df['description_length']]\n",
    "var_df.to_csv('fin/variables.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence of preview video: 900\n",
      "Video with teacher face: 900, 0.401, 0.490\n",
      "Video quality: 900, 0.725, 0.081, 0.379, 0.930\n",
      "Video length: 900, 196.325, 204.122, 10.067, 2132.708\n",
      "Average smiling duration: 361, 0.103, 0.143,        0.000, 0.840\n",
      "Beginning duration: 361, 0.112, 0.164,         0.000, 1.000\n",
      "Middle duration: 361, 0.088, 0.138,         0.000, 0.889\n",
      "End duration: 361, 0.108, 0.157,         0.000, 0.928\n",
      "Average smiling intensity: 361, 0.401, 0.126,         0.113, 0.771\n",
      "Facial symmetry: 361, 0.629, 0.235,         0.065, 1.326\n"
     ]
    }
   ],
   "source": [
    "## preview video\n",
    "print(f'Presence of preview video: {len(var_df)}')\n",
    "print(f'Video with teacher face: {len(var_df)}, {np.mean(var_df.showup):.3f}, {np.std(var_df.showup):.3f}')\n",
    "print(f'Video quality: {len(var_df)}, {np.mean(var_df.quality):.3f}, {np.std(var_df.quality):.3f}, {np.min(var_df.quality):.3f}, {np.max(var_df.quality):.3f}')\n",
    "print(f'Video length: {len(var_df)}, {np.mean(var_df.video_length):.3f}, {np.std(var_df.video_length):.3f}, {np.min(var_df.video_length):.3f}, {np.max(var_df.video_length):.3f}')\n",
    "print(f'Average smiling duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].smile_proportion):.3f}, {np.std(var_df.loc[var_df.showup==1].smile_proportion):.3f},\\\n",
    "        {np.min(var_df.loc[var_df.showup==1].smile_proportion):.3f}, {np.max(var_df.loc[var_df.showup==1].smile_proportion):.3f}')\n",
    "print(f'Beginning duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].beginning):.3f}, {np.std(var_df.loc[var_df.showup==1].beginning):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].beginning):.3f}, {np.max(var_df.loc[var_df.showup==1].beginning):.3f}')\n",
    "print(f'Middle duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].middle):.3f}, {np.std(var_df.loc[var_df.showup==1].middle):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].middle):.3f}, {np.max(var_df.loc[var_df.showup==1].middle):.3f}')\n",
    "print(f'End duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].end):.3f}, {np.std(var_df.loc[var_df.showup==1].end):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].end):.3f}, {np.max(var_df.loc[var_df.showup==1].end):.3f}')\n",
    "print(f'Average smiling intensity: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].Intensity):.3f}, {np.std(var_df.loc[var_df.showup==1].Intensity):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].Intensity):.3f}, {np.max(var_df.loc[var_df.showup==1].Intensity):.3f}')\n",
    "print(f'Facial symmetry: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].asymmetry):.3f}, {np.std(var_df.loc[var_df.showup==1].asymmetry):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].asymmetry):.3f}, {np.max(var_df.loc[var_df.showup==1].asymmetry):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 900, 0.913, 0.281, 0.000, 1.000\n",
      "Teacher rating: 900, 4.318, 0.280, 2.567, 4.924\n",
      "Log number of students: 900, 10.020, 1.998, 5.204, 14.745\n",
      "Number of courses: 900, 23.764, 31.472, 1.000, 220.000\n"
     ]
    }
   ],
   "source": [
    "## teacher characteristics\n",
    "print(f'Male: {len(var_df)}, {np.nanmean(var_df.male):.3f}, {np.nanstd(var_df.male):.3f}, {np.nanmin(var_df.male):.3f}, {np.nanmax(var_df.male):.3f}')\n",
    "print(f'Teacher rating: {len(var_df)}, {np.mean(var_df.Rating_of_Tch_1):.3f}, {np.std(var_df.Rating_of_Tch_1):.3f}, {np.min(var_df.Rating_of_Tch_1):.3f}, {np.max(var_df.Rating_of_Tch_1):.3f}')\n",
    "print(f'Log number of students: {len(var_df)}, {np.nanmean(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanstd(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanmin(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanmax(np.log(var_df.Students_of_Tch_1)):.3f}')\n",
    "print(f'Number of courses: {len(var_df)}, {np.mean(var_df.Courses_of_Tch_1):.3f}, {np.std(var_df.Courses_of_Tch_1):.3f}, {np.min(var_df.Courses_of_Tch_1):.3f}, {np.max(var_df.Courses_of_Tch_1):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log length of course description: 900, 2.664, 0.366, 0.693, 3.258\n",
      "Selling price: 900, 17.940, 15.790, 0.000, 199.990\n",
      "Log number of student enrollment: 900, 8.033, 1.381, 5.204, 12.647\n",
      "Course rating: 900, 4.291, 0.390, 1.862, 5.000\n"
     ]
    }
   ],
   "source": [
    "## course characteristics\n",
    "print(f'Log length of course description: {len(var_df)}, {np.nanmean(var_df.log_description_length):.3f}, {np.nanstd(var_df.log_description_length):.3f}, {np.nanmin(var_df.log_description_length):.3f}, {np.nanmax(var_df.log_description_length):.3f}')\n",
    "print(f'Selling price: {len(var_df)}, {np.mean(var_df.Selling_Price):.3f}, {np.std(var_df.Selling_Price):.3f}, {np.min(var_df.Selling_Price):.3f}, {np.max(var_df.Selling_Price):.3f}')\n",
    "print(f'Log number of student enrollment: {len(var_df)}, {np.nanmean(np.log(var_df.Students_Num)):.3f}, {np.nanstd(np.log(var_df.Students_Num)):.3f}, {np.nanmin(np.log(var_df.Students_Num)):.3f}, {np.nanmax(np.log(var_df.Students_Num)):.3f}')\n",
    "print(f'Course rating: {len(var_df)}, {np.nanmean(var_df.Rating):.3f}, {np.nanstd(var_df.Rating):.3f}, {np.nanmin(var_df.Rating):.3f}, {np.nanmax(var_df.Rating):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dependent variables and control variables\n",
    "category = 'pd'\n",
    "info = pd.read_excel('pd/x897.xlsx')\n",
    "info.rename(columns={'Id': 'Video_ID'}, inplace=True)\n",
    "## duration\n",
    "dur_df = pd.read_csv('pd/duration_freq5.csv', sep='\\t')\n",
    "## timing\n",
    "tim_df = pd.read_csv('pd/timing_3_freq5.csv', sep='\\t')\n",
    "## intensity\n",
    "inten_df = pd.read_csv('pd/intensity_freq5.csv', sep='\\t')\n",
    "## asymmetry\n",
    "asym_df = pd.read_csv('pd/asymmetry_freq5.csv', sep='\\t')\n",
    "## beauty\n",
    "beauty_df = pd.read_csv('pd/beauty_freq5.csv', sep='\\t')\n",
    "## video quality\n",
    "qua_df = pd.read_csv('pd/video_quality.txt', sep='\\t', header=None)\n",
    "qua_df.columns = ['Video_ID', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 897/897 [00:01<00:00, 572.04it/s]\n"
     ]
    }
   ],
   "source": [
    "video_folders = ['pd_1-100', 'pd_101-200', 'pd_201-300', 'pd_301-400', 'pd_401-500',\n",
    "                 'pd_501-600', 'pd_601-700', 'pd_701-800', 'pd_801-897']\n",
    "video_paths = [f'{category}/{x}' for x in video_folders]\n",
    "video_lookup = dict.fromkeys(video_folders)\n",
    "for i, k in enumerate(video_lookup.keys()):\n",
    "    video_lookup[k] = [os.path.splitext(x)[0] for x in os.listdir(f'/home/xyubl/Downloads/{k}')]\n",
    "video_lookup_inv = {}\n",
    "for k, v in video_lookup.items():\n",
    "    for vid in v:\n",
    "        video_lookup_inv[vid] = f'/home/xyubl/Downloads/{k}/{vid}.mp4'\n",
    "path_df = pd.DataFrame(columns=['Video_ID', 'path'])\n",
    "for k, v in tqdm(video_lookup_inv.items()):\n",
    "    path_df.loc[len(path_df)] = [k, v]\n",
    "path_df = path_df.astype({'Video_ID': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gender estimation and manually correction: do not run\n",
    "if False:\n",
    "    d = gender.Detector()\n",
    "    gender_df = pd.DataFrame(columns=['Name_of_Tch_1', 'gender'])\n",
    "    for name in tqdm(set(info.Name_of_Tch_1.values.tolist())):\n",
    "        est = d.get_gender(name.split(' ')[0])\n",
    "        gender_df.loc[len(gender_df)] = [name, est]\n",
    "    gender_df = pd.merge(info[['Video_ID', 'Name_of_Tch_1']], gender_df[['Name_of_Tch_1', 'gender']], on='Name_of_Tch_1')\n",
    "    df = pd.merge(gender_df, path_df, on='Video_ID', how='left')\n",
    "    df.to_excel('pd/gender_estimation.xlsx', index=False)\n",
    "    gender_df = pd.read_excel('pd/gender.xlsx')\n",
    "    gender_df.to_csv('pd/gender.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gender\n",
    "gender_df = pd.read_csv('pd/gender.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## video length\n",
    "if not os.path.exists('fin/video_length.csv'):\n",
    "    video_folders = ['pd_1-100', 'pd_101-200', 'pd_201-300', 'pd_301-400', 'pd_401-500',\n",
    "                     'pd_501-600', 'pd_601-700', 'pd_701-800', 'pd_801-897']\n",
    "    video_paths = [f'/home/xyubl/Downloads/{x}' for x in video_folders]\n",
    "    len_df = pd.DataFrame(columns=['Video_ID', 'video_length'])\n",
    "    for video_path in video_paths:\n",
    "        video_files = glob.glob(f'{video_path}/*.mp4')\n",
    "        for video_file in tqdm(video_files):\n",
    "            video_id = int(video_file.split('/')[-1].split('.')[0])\n",
    "            video = cv2.VideoCapture(video_file)\n",
    "            frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "            fps = video.get(cv2.CAP_PROP_FPS) \n",
    "            video_length = frames / fps\n",
    "            len_df.loc[len(len_df)] = [video_id, video_length]\n",
    "    len_df = len_df.astype({'Video_ID': int})\n",
    "    len_df.to_csv('pd/video_length.csv', sep='\\t', index=False)\n",
    "len_df = pd.read_csv('pd/video_length.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter information\n",
    "filter_df = pd.read_csv('pd/video_filter.csv', sep='\\t')\n",
    "use_videos = filter_df.loc[(filter_df.showup_proportion>0.2) & (filter_df.frame_land_diff>3) & (filter_df.align_land_diff>3)].Video_ID.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate all variables\n",
    "dfs = [info, dur_df[['Video_ID', 'showup', 'smile_proportion']], tim_df[['Video_ID', 'beginning', 'middle', 'end']], \n",
    "       inten_df[['Video_ID', 'Intensity']], asym_df[['Video_ID', 'asymmetry']], beauty_df[['Video_ID', 'beauty']],\n",
    "       qua_df, len_df, gender_df, path_df]\n",
    "var_df = reduce(lambda left, right: pd.merge(left, right, on='Video_ID', how='outer'), dfs)\n",
    "var_df['preview'] = (~var_df.path.isna().values).astype(int)\n",
    "showup_arr = []\n",
    "for _, row in var_df.iterrows():\n",
    "    if row.preview == 0:\n",
    "        showup_arr.append(np.nan)\n",
    "    else:\n",
    "        showup_arr.append(int(row.Video_ID in use_videos))\n",
    "var_df.showup = showup_arr\n",
    "var_df = var_df.sort_values('Video_ID').reset_index(drop=True)\n",
    "var_df['male'] = [1 if x in ['male', 'unknown'] else 0 for x in var_df.gender]\n",
    "var_df['description_length'] = var_df['Blurb'].apply(lambda x: len(x.split(' ')) if type(x) is str else 0)\n",
    "var_df['log_description_length'] = [np.log(x) if x != 0 else 0 for x in var_df['description_length']]\n",
    "var_df.to_csv('pd/variables.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence of preview video: 897\n",
      "Video with teacher face: 897, 0.692, 0.462\n",
      "Video quality: 897, 0.744, 0.075, 0.484, 0.958\n",
      "Video length: 897, 172.217, 184.258, 15.633, 3542.200\n",
      "Average smiling duration: 621.000, 0.123, 0.173,        0.000, 0.886\n",
      "Beginning duration: 621, 0.130, 0.192,         0.000, 1.000\n",
      "Middle duration: 621, 0.110, 0.171,         0.000, 1.000\n",
      "End duration: 621, 0.130, 0.189,         0.000, 1.000\n",
      "Average smiling intensity: 621, 0.425, 0.121,         0.128, 0.894\n",
      "Facial symmetry: 621, 0.608, 0.231,         0.001, 1.234\n"
     ]
    }
   ],
   "source": [
    "## preview video\n",
    "print(f'Presence of preview video: {sum(var_df.preview)}')\n",
    "print(f'Video with teacher face: {sum(var_df.preview)}, {np.mean(var_df.showup):.3f}, {np.std(var_df.showup):.3f}')\n",
    "print(f'Video quality: {sum(var_df.preview)}, {np.nanmean(var_df.quality):.3f}, {np.nanstd(var_df.quality):.3f}, {np.nanmin(var_df.quality):.3f}, {np.nanmax(var_df.quality):.3f}')\n",
    "print(f'Video length: {sum(var_df.preview)}, {np.nanmean(var_df.video_length):.3f}, {np.nanstd(var_df.video_length):.3f}, {np.nanmin(var_df.video_length):.3f}, {np.nanmax(var_df.video_length):.3f}')\n",
    "print(f'Average smiling duration: {len(var_df.loc[var_df.showup==1]):.3f}, {np.mean(var_df.loc[var_df.showup==1].smile_proportion):.3f}, {np.std(var_df.loc[var_df.showup==1].smile_proportion):.3f},\\\n",
    "        {np.min(var_df.loc[var_df.showup==1].smile_proportion):.3f}, {np.max(var_df.loc[var_df.showup==1].smile_proportion):.3f}')\n",
    "print(f'Beginning duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].beginning):.3f}, {np.std(var_df.loc[var_df.showup==1].beginning):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].beginning):.3f}, {np.max(var_df.loc[var_df.showup==1].beginning):.3f}')\n",
    "print(f'Middle duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].middle):.3f}, {np.std(var_df.loc[var_df.showup==1].middle):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].middle):.3f}, {np.max(var_df.loc[var_df.showup==1].middle):.3f}')\n",
    "print(f'End duration: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].end):.3f}, {np.std(var_df.loc[var_df.showup==1].end):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].end):.3f}, {np.max(var_df.loc[var_df.showup==1].end):.3f}')\n",
    "print(f'Average smiling intensity: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].Intensity):.3f}, {np.std(var_df.loc[var_df.showup==1].Intensity):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].Intensity):.3f}, {np.max(var_df.loc[var_df.showup==1].Intensity):.3f}')\n",
    "print(f'Facial symmetry: {len(var_df.loc[var_df.showup==1])}, {np.mean(var_df.loc[var_df.showup==1].asymmetry):.3f}, {np.std(var_df.loc[var_df.showup==1].asymmetry):.3f}, \\\n",
    "        {np.min(var_df.loc[var_df.showup==1].asymmetry):.3f}, {np.max(var_df.loc[var_df.showup==1].asymmetry):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 687, 0.723, 0.447, 0.000, 1.000\n",
      "Teacher rating: 950, 4.405, 0.249, 3.116, 5.000\n",
      "Log number of students: 950, 9.948, 1.959, 5.357, 14.311\n",
      "Number of courses: 950, 24.348, 46.907, 1.000, 454.000\n"
     ]
    }
   ],
   "source": [
    "## teacher characteristics\n",
    "print(f'Male: {len(var_df.loc[var_df.male==1])}, {np.nanmean(var_df.male):.3f}, {np.nanstd(var_df.male):.3f}, {np.nanmin(var_df.male):.3f}, {np.nanmax(var_df.male):.3f}')\n",
    "print(f'Teacher rating: {len(var_df)}, {np.mean(var_df.Rating_of_Tch_1):.3f}, {np.std(var_df.Rating_of_Tch_1):.3f}, {np.min(var_df.Rating_of_Tch_1):.3f}, {np.max(var_df.Rating_of_Tch_1):.3f}')\n",
    "print(f'Log number of students: {len(var_df)}, {np.nanmean(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanstd(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanmin(np.log(var_df.Students_of_Tch_1)):.3f}, {np.nanmax(np.log(var_df.Students_of_Tch_1)):.3f}')\n",
    "print(f'Number of courses: {len(var_df)}, {np.mean(var_df.Courses_of_Tch_1):.3f}, {np.std(var_df.Courses_of_Tch_1):.3f}, {np.min(var_df.Courses_of_Tch_1):.3f}, {np.max(var_df.Courses_of_Tch_1):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log length of course description: 950, 2.640, 0.377, 1.099, 3.219\n",
      "Selling price: 950, 13.738, 21.785, 9.990, 199.990\n",
      "Log number of student enrollment: 950, 8.241, 1.295, 5.357, 11.659\n",
      "Course rating: 950, 4.396, 0.328, 2.591, 5.000\n"
     ]
    }
   ],
   "source": [
    "## course characteristics\n",
    "print(f'Log length of course description: {len(var_df)}, {np.nanmean(var_df.log_description_length):.3f}, {np.nanstd(var_df.log_description_length):.3f}, {np.nanmin(var_df.log_description_length):.3f}, {np.nanmax(var_df.log_description_length):.3f}')\n",
    "print(f'Selling price: {len(var_df)}, {np.mean(var_df.Selling_Price):.3f}, {np.std(var_df.Selling_Price):.3f}, {np.min(var_df.Selling_Price):.3f}, {np.max(var_df.Selling_Price):.3f}')\n",
    "print(f'Log number of student enrollment: {len(var_df)}, {np.nanmean(np.log(var_df.Students_Num)):.3f}, {np.nanstd(np.log(var_df.Students_Num)):.3f}, {np.nanmin(np.log(var_df.Students_Num)):.3f}, {np.nanmax(np.log(var_df.Students_Num)):.3f}')\n",
    "print(f'Course rating: {len(var_df)}, {np.nanmean(var_df.Rating):.3f}, {np.nanstd(var_df.Rating):.3f}, {np.nanmin(var_df.Rating):.3f}, {np.nanmax(var_df.Rating):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate two categories into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 37), (950, 37))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df = pd.read_csv('fin/variables.csv', sep='\\t')\n",
    "pd_df = pd.read_csv('pd/variables.csv', sep='\\t')\n",
    "fin_df['category'] = 'finance'\n",
    "pd_df['category'] = 'personal development'\n",
    "fin_df.shape, pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([fin_df, pd_df], axis=0)\n",
    "all_df.to_csv('all_variables.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
